<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Nathanael Aff" />


<title>Training the model</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 71px;
  margin-top: -71px;
}

.section h2 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h3 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h4 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h5 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h6 {
  padding-top: 71px;
  margin-top: -71px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">legolda</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/nateaff/legolda">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Training the model</h1>
<h4 class="author"><em>Nathanael Aff</em></h4>

</div>


<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
<!-- Insert last udpate and git version-->
<p><strong>Last updated:</strong> 2017-09-22</p>
<p><strong>Code version:</strong> 37e505a</p>
<div id="selecting-a-topic-model" class="section level1">
<h1>Selecting a topic model</h1>
<p>As with kmeans clustering the LDA model requires the number of topics <span class="math inline">\(k\)</span> to be selected by the user. In this section we test out several methods that could be used to automate the scoring and selection</p>
<div id="cross-validation-on-perplexity" class="section level2">
<h2>Cross validation on perplexity</h2>
<p>The LDA model learns to posterior distributions which are the optimization routine’s best guess at the distributions that generated the data. One method to test how good those distributions fit our data is to compare the learned distribution on a training set to the distribution of a holdout set. Perplexity is one measure of the difference between estimated topic distributions on documents.</p>
<p>We cast the set_word table to a document term matrix using the <code>tidytext</code> function. This returns a<code>documentTermMatrix</code> object from the <code>tm</code> package. The LDA function we use is from the <code>topicmodels</code> package. It has a variational expectation maximation method and a Gibbs sampling method and I used the former.</p>
<pre><code>Loading datasets from CSV files 
Assigning themes to theme_df 
Assigning full set set inventories to &#39;set_colors&#39; 
Assigning values to total_words
Assigning tidy set and color dataframe to &#39;set_words&#39; 
Creating sparse document term matrix (tm-package) and assigning to &#39;dtm&#39; </code></pre>
<pre class="r"><code>perplexities &lt;- readRDS(here::here(&quot;inst&quot;, &quot;data&quot;, &quot;perplexity_all.RDS&quot;))</code></pre>
<div id="k-topic-grid" class="section level3">
<h3>K-topic grid</h3>
<p>Since I tested the running time on different set numbers I have seen that for this small number of sets there aren’t many topics. I have included a few more topic values <span class="math inline">\(k\)</span> on the lower end but including some higher values to better see the trend.</p>
<pre class="r"><code>perplexities %&gt;% ggplot(aes(n_topic, perplexity)) + geom_point(aes(colour = fold), 
    size = 2) + geom_line(aes(n_topic, perplexity, group = fold, colour = fold)) + 
    scale_color_manual(values = pal21(), guide = guide_legend(title = &quot;Folds&quot;)) + 
    geom_smooth(se = FALSE, colour = &quot;#2f2f2a&quot;) + scale_x_continuous(breaks = perplexities$n_topic) + 
    labs(x = &quot;Number of topics&quot;, y = &quot;Perplexity&quot;, title = &quot;Perplexity scores for LDA models&quot;, 
        subtitle = &quot;Perplexity (lower is better) of holdout sets for 5-fold cross-validation&quot;) + 
    legolda::theme_scatter(bgcol = &quot;#f8f8f8&quot;)</code></pre>
<p><img src="figure/train-model.Rmd/cv-result-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ntopics &lt;- c(20, 30, 35, 40, 50, 75, 100)
# Train LDA models on full data set
if (!from_cache) {
    lda_models &lt;- c(20, 30, 35, 40, 50, 75, 100) %&gt;% purrr::map(LDA, x = dtm, 
        control = list(seed = 1))
}</code></pre>
</div>
</div>
<div id="ldatuning-topic-scores" class="section level2">
<h2><code>ldatuning</code> topic scores</h2>
<p>The <code>ldatuning</code> package has several other metrics of the quality of the topic models. I have modified the main function from the package to only return the scores. (The original package computes the models first and then the scores).</p>
<pre class="r"><code>knitr::read_chunk(here::here(&quot;code&quot;, &quot;ldatuning-scores.R&quot;))</code></pre>
<pre class="r"><code>lda_models &lt;- readRDS(here::here(&quot;inst&quot;, &quot;data&quot;, &quot;lda_models_all.RDS&quot;))
lda_metrics &lt;- legolda::score_models(lda_models, dtm, topics = ntopics)

plot_lda_scores(lda_metrics, title)</code></pre>
<p><img src="figure/train-model.Rmd/ldatuning-scores-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="topic-coherence" class="section level2">
<h2>Topic coherence</h2>
<p>There are several version of topic coherence which measure the pairwise strength of the relationship of the top terms in a topic model. Given some score where a larger value indicates a stronger relation ship between two words <span class="math inline">\(w_i, w_j\)</span>, a generic coherence score is the sum over the top terms in a topic model:<br />
<span class="math display">\[ \sum_{w_i, w_j \in W_t} \text{Score}(w_i, w_j), \]</span> with top terms <span class="math inline">\(W_t\)</span> for each topic <span class="math inline">\(t\)</span>.</p>
<p>The coherence score used in the <code>SpeedReader</code> coherence function just uses the internal coherence of the top terms. I compared the scores for the top 3, 5 and 10 terms.</p>
<pre class="r"><code>coh_tbl &lt;- readRDS(here::here(&quot;inst&quot;, &quot;data&quot;, &quot;coherence.RDS&quot;))
coh_tbl &lt;- coh_tbl %&gt;% mutate(nterms = forcats::fct_inorder(nterms))

# TODO: sort number of terms in order

coh_tbl %&gt;% ggplot(aes(x = ntopics, y = coherence, group = nterms)) + geom_point(aes(colour = nterms, 
    group = nterms), size = 2) + geom_line(aes(color = nterms)) + scale_color_manual(values = pal21(), 
    guide = guide_legend(title = &quot;Number of terms&quot;)) + scale_x_continuous(breaks = coh_tbl$ntopics) + 
    labs(x = &quot;Number of topics&quot;, y = &quot;Coherence&quot;, title = &quot;Term coherence of LDA models&quot;, 
        subtitle = &quot;Coherence scores (higher is better) for the top 3, 5 and 10 terms&quot;) + 
    theme_scatter(bgcol = &quot;#f8f8f8&quot;)</code></pre>
<p><img src="figure/train-model.Rmd/coherence-score-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="cluster-scoring" class="section level2">
<h2>Cluster scoring</h2>
<p>We can also treat the LDA models as clustering the LEGO sets. We can assign the LEGO set to the color topic which has the highest value for that document; This is the topic that is most responsible for generating the document.</p>
<p>The previous plot should indicate whether documents are getting strongly associated with a topic or if topics are to evenly distributed over all documents.</p>
<div id="clustering-sets-with-kmeans" class="section level3">
<h3>Clustering sets with kmeans</h3>
<p>In this next section, I cluster documents using both kmeans and LDA topics. Kmeans is intended as a simple baseline clustering method and sets are clustered based on their term vectors weighted by TF-IDF scores.</p>
</div>
<div id="cluster-analysis" class="section level3">
<h3>Cluster analysis</h3>
<p>The clusters scores include Rand, adjusted Rand, Folkes-Mallow and Jaccard scores. All try to score a clustering on how well the discovered labels match the assigned labels – here the <code>root_id</code> of the set. The Rand index assigns a score based on the number pairwise agreement of the cluster labels with the original labels. The other measures are somewhat similar in approach.</p>
</div>
</div>
<div id="topic-distribution" class="section level2">
<h2>Topic Distribution</h2>
<p>Another way to evaluate the quality of the topic models is to see how well documents are sorted into topics. This example follows a <a href="http://tidytextmining.com/nasa.html#calculating-tf-idf-for-the-description-fields">this section</a> from the tidy text mining book.</p>
<p>The topic model’s gamma matrix has the distribution of topics over models: <span class="math display">\[
 \text{gamma}  = p(t|d)
\]</span> for topic <span class="math inline">\(t\)</span> and document <span class="math inline">\(d\)</span>.</p>
<p>The plot below visualizes this as how the <em>topics</em> are distributed over the probability bins for each topic. If too many topics have sets or documents in the low probability bins then you may have too high a number of topics since few documents are being strongly associated with any topic.</p>
<p>Following the tidytext book, look at the distribution over topics.</p>
<p><img src="figure/train-model.Rmd/plot-40-topics-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
